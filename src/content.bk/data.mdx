---
layout: page
title: "Data"
date: "2018"
description: "Oh, the data you'll meet"

---

All neural nets begin with data, on both a conceptual level and a physical level.

A neural net, at its core, is just a set of mathematical functions - theory represented in code. Neural nets only come "alive" in the presence of data.

## Types of Data

What is data? Data are the things you measure, the things you make predictions on.

Data can be anything representable in numeric form in a computer. It can be numbers, or tabular data. It can be images, audio, or video. It can be text, PDFs, documents, webpages. It can be laser recordings from the top of autonomous cars, EMRs from medical devices, even EKGs from brain waves. If it can be represented in numerical form - and really, anything we can measure is capable of becoming numeric - then it can be data.

The particular nature of your data will dictate everything about the Neural Network that you build.

## Bugs

As programmers, we're used to syntactic errors. Things like missing definitions, variables used before they're defined, that sort of thing. We have a rich ecosystem of tools - IDEs, compilers - designed to help us mitigate these bugs and catch them before they reach an end user, and these tools are very good.

With neural nets, there's two more classes of bugs you'll encounter. Data bugs and model bugs.

Data bugs can manifest in a number of ways. If you're dealing with images, you might have mislabeled images, or images transformed or processed incorrectly.

If you're dealing with text, maybe it's text that's cut off, garbled, or in the wrong format - ASCII when it should be in UTF-8.

<img src="glitch.png" />

Then there's bugs in your data - mislabeled things, images that are transformed incorrectly, processed incorrectly. Maybe if text, it's text that's cut off, or garbled, or in ASCII when it should be in UTF-8. All that stuff's important.

Many of these bugs are simple to catch in isolated cases but can sneak in perniciously under the radar and cause your model to train wrong. If you're working with large datasets, cleaning your data becomes a bear.

Then there's model bugs - bugs that arise from the way you've designed your neural network.

These tend not to manifest themselves as catastrophic failures, but in an inability of the neural net to perform the way you hope it will. When working in a novel domain, it is often hard to know what exactly to expect from yoru model's accuracy, making these bugs even more pernicious; if you don't even know how effective your model *should* be, then what?

One way to mitigate these network bugs is to start small. Take the smallest possible dataset, one you know inside and out, and start with a simple neural network that others have benchmarked. Build things iteratively, testing your accuracy and loss every step of the way, and adding complexity one step at a time.

We'll take this approach in the next section, by starting with the simplest possible dataset, and making it more complex as we proceed.

## Non-Linearity

The importance of non linearity - activation functions.

Concatenating data together. memory management. Typed Arrays.

Tensors.

## Code


We've been talking about our **training data** as a monolithic collection. In fact, we will consistently separate our data into "features" and "labels". Our features are the images themselves, and the labels describe which category they should be. You need these to be in the same order - matched up - but you also need them to be discrete tensors.

Let's talk tensors.

All neural nets deal in numbers. Whether your training data consists of images, audio, text or some other exotic data format, you will need to convert it into numbers for consumption by the machine. The particular method to do this will depend on your data and may often be bespoke to your particular use case. Labels are the same - you will need to take your string labels - "category one " and "category two" - and turn these into numbers.

Your numbers, for images, might be the pixel data. For audio, the samples, or maybe a Fourier transform. For text, it might be numeric encodings for each word.

For labels, we often do something called "one hot encoding". What that means is this:

[Diagram of one hot]

The reason we do this is blah blah.

So what is a tensor? Let's talk tensors.

Let's look at them in code.

```
tf.tensor1d();
```

You can't console.log a tensor effectively. You can print it, or you can dataSync it.
