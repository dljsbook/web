---
layout: page
title: "Training"
date: "2018"
description: "An Overview of the Training Process of a Neural Net"

---


Training a computer is sort like training a dog. We'll ride this metaphor as far as it'll take us.

When training a dog, first, the dog has to demonstrate the behavior you're trying to train. For instance, if you're training them to sit - let's call this an **example**. Once the dog has done the behavior, you give the dog some **reward**, like a treat. In this way, the **example** is associated with a **reward**. You then repeat this process, over and over, until the dog gets it. This **repetition** helps cement the link between the behavior and the expected reward.

It turns out that these three things are also used to train a machine. Let's examine each of these and see how they apply to deep learning.

## Examples

When you train a dog, you need examples of the behavior you wish to reward. Similarly, with a neural network, you compile a list of examples that demonstrate what you wish the network to learn. These examples comprise your total dataset.

Often (though not always), you will split your data into buckets randomly. The buckets are called Train, Test, and Validation sets.

https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7


You've got a well balanced training dataset that you're shuffling consistently, and its representative of your real life data. How do you know how well your model is performing on this data? You can measure this by setting aside chunks of your dataset as **test data** and **validation data**.

### Training Data

This is the bulk of your dataset; this is the data your model consumes and learns from.

### Test Data

You test the performance of your model against a holdout set of data commonly referred to as a **test dataset**. (*Different folks use different names for the same underlying concepts, which can make it hard when first learning. Learn the concepts and you'll be able to adapt no matter the language used*).

A **test dataset** is data the machine *has never seen before*. You hold it in reserve, like a savings account. Just like your **training data**, this data consists of both examples and labels, but because this is data the model has never encountered, it serves as a useful barometer for how accurate your model performs. (Remember, this dataset should also be representative - it should not differ substantially from your training dataset).

While its important to get good accuracy on your training dataset, the true test of your model is the score for your **test dataset**. If you can score well against this data, you're golden.

*Is your dataset balanced? I can't tell - I'm just a book - but look to see whether the test data is representative of your training data.*

### Validation Data

There's a third bucket you might separate, a **validation set**. This is similar to the test set from above, in that its some portion of your dataset that is held back during training, and used to measure the accuracy *during* training.

Validation data can either be a set slab of data separated before training begins, or it can be randomly selected at the start of each epoch. The former provides a more accurate ready of the model's ongoing performance, but can rob you of precious data if you don't have much.

Validation data especially helps with tuning hyperparameters.

If you have enough data, setting aside a dedicated validation portion can be a good strategy, since it gives you confidence that the accuracy is based on the model learning independently of the validation data. If you're dealing with smaller datasets, and in the browser we often are, data is your most precious resource and you want to be strategic in how you deploy it. In these cases, setting aside a small portion each cycle can make more sense. In this case, make sure
to slice this off after you shuffle, so you're always testing on a different portion.

How much data should make up each dataset? It depends. For datasets upwards of 100,000 data points, 10,000 points each for test and validation sets is more than enough and you shouldn't exceed 10,000. For smaller datasets, it depends on how big your dataset is, and how complex your model is. A very rough starting point is 80% for training, and 10% each for validation and test, but you'll have to experiment with this.

Anyways - we're now giving the model a tensor of input values, and a tensor of labels. We wish for our predicted values to match up perfectly with the provided labels. The difference with this reality - how wrong the model is - is the parameter we wish to improve.

## Practice

Iteration, hyperparameters (learning rate)

You wouldn't expect your dog to learn a trick on the first try; hell, sometimes not even on the hundredth try. Similarly, a neural network needs to work through many attempts before it's able to hone on correct answers.

The training process is an **iterative** one. It takes multiple cycles of training to get better. The more data, and the more complex the data, the more cycles of training you will need. The more complex the model, the more cycles of training you need. The more accurate you want your model to be, the more cycles of training you will need (up to a point - too many cycles can actually
lead to overfitting which we will touch on later).

Let's see an example. Here's a simple line with a slope of 2.

[LINE] - maybe you can modify slope and intercept?

If I ask you to look at this line and predict the value of **Y** if **X** is 5, you could figure it the answer was 10 just by looking at the line. Our neural net cannot do this. Remember, it has no inherent intelligence - no ability to deduce using reasoning and logic. The only way it can learn is iteratively, through repeated training on data that we feed it.

With this, you can hover over the graph to see what the model predicts a value at. Click to leave a point on the graph.

[GRAPH]

In its default state, the network makes random predictions. That's because the component parts of the neural network are initialized randomly. The component parts in this case are the "weights". What are weights?

Weights make up a large part of what neural nets do. Here's a live diagram:

[NN]

Change weights. See what that does to different input values. These weights* are the things that the neural network changes as it trains. *There are also biases.

Let's go back to our line. It's pretrained. You can slide the slider to see the predictions and how they change over time.

[EXAMPLE]

What is an epoch?

You can also see the weights of the model changing over time:

[NN with slider]

One thing to emphasize here is that the network gets better, iteravitely, over time. It probably will never be perfect. This is an important mental shift from traditional software engineering. You have to become comfortable with a realm of acceptability.

In general, the more cycles of training you can afford, the better the model will be. There are limits to this, like overfitting, which we will discuss later. One way of increasing the number of cycles is by using "minibatches", where you take chunks of your data. Often times, this is a necessity borne out of memory - especially on servers, where its infeasible to train on gigabytes at a time, but especially in the browser, where adding big chunks of data into memory can block the UI.

Speaking of blocking the UI, tfjs provides two important memory management methods:

tf.tidy
tf.awaitFrame

use them.


## Rewards

Loss

Forward and backward propagation


* here, dig into loss, and other goodies
    * explain how forward propagation works. how does a network wind up with a prediction?
        * expanding tensor dimensions, and concatenating
    * talk about how loss is the sum of the differences
        * talk about how you want to minimize loss, and how you do that with gradient descent
        * talk about what kinds of losses there are

[Comic of dog with human saying a bunch of nonsense, and dog listening for the food parts]

Rewards are what makes training possible. For dogs, its food. For neural networks, its something called **loss**.

Loss is a measure of how wrong a network's predictions are. The network is incentivized to reduce loss as much as possible; that's its reward. (Pretty meager, I know; who am I to judge what motivates a computer!)

Let's go back to our line example, and see our loss for epoch 0:

[SHOW NUMBERS]

Then, let's see it at epoch 1:

[SHOW NUMBERS]

As is evident, the loss from epoch 1 is lower than epoch 0. The network is "learning".

Here's some formal terms for ya: **forward propagation** is sending numbers through the network, and **backwards propagation** is basically sending data backwards through the network. This backwards step is how the network trains.

Let's see a simple example. We start with totally randomized weights. We then send some numbers through the network. We get our loss. We then adjust the weights some large amount, TIMES what's called the learning rate. Learning rate represents a **hyperparameter** - an argument you can tune in the network to get better results. There's no right answer for what this should be, but there are guidelines.

Why don't we want to just take a big leap? Iteration is the key. You could overshoot. Let's see an example - if we had a huge learning rate. In fact, you can play with the learning rate.

So we're tweaking the weights. What are weights? Well, that leads us into our next section: the architecture of your model.


---

## Code

Let's look at some code. Here's our training function:

```
import model from '@dljsbook/models/image_classification';
model.fit(training_data, training_labels, {
  callbacks: 
});
```

